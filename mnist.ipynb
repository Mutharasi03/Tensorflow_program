{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (8.1.7)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting immutabledict (from tensorflow_datasets)\n",
      "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (1.26.2)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (4.25.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (5.9.6)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (14.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (2.31.0)\n",
      "Collecting simple-parsing (from tensorflow_datasets)\n",
      "  Downloading simple_parsing-0.1.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (4.66.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Collecting etils>=1.9.1 (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading etils-1.9.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (2024.6.0)\n",
      "Collecting importlib_resources (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (4.9.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->tensorflow_datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\gaming3\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting docstring-parser~=0.15 (from simple-parsing->tensorflow_datasets)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf>=3.20 (from tensorflow_datasets)\n",
      "  Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Downloading tensorflow_datasets-4.9.6-py3-none-any.whl (5.1 MB)\n",
      "   ---------------------------------------- 0.0/5.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/5.1 MB 3.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.3/5.1 MB 4.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.6/5.1 MB 5.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.1/5.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.6/5.1 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.1/5.1 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.1/5.1 MB 8.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.8/5.1 MB 7.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.9/5.1 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.4/5.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.9/5.1 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.3/5.1 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.8/5.1 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.1/5.1 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.1/5.1 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading etils-1.9.2-py3-none-any.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/161.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 161.5/161.5 kB 10.1 MB/s eta 0:00:00\n",
      "Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.3/101.3 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading simple_parsing-0.1.5-py3-none-any.whl (113 kB)\n",
      "   ---------------------------------------- 0.0/113.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 113.6/113.6 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
      "Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 413.4/413.4 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
      "   ---------------------------------------- 0.0/229.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 229.2/229.2 kB 13.7 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21545 sha256=46ded23a0e468c1bd3764c84b4e23540eed92b3a69dc49b6efdcd7c9383d9345\n",
      "  Stored in directory: c:\\users\\gaming3\\appdata\\local\\pip\\cache\\wheels\\90\\74\\b1\\9b54c896b8d9409e9268329d4d45ede8a8040abe91c8879932\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, protobuf, promise, importlib_resources, immutabledict, etils, docstring-parser, simple-parsing, googleapis-common-protos, tensorflow-metadata, tensorflow_datasets\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.1\n",
      "    Uninstalling protobuf-4.25.1:\n",
      "      Successfully uninstalled protobuf-4.25.1\n",
      "Successfully installed dm-tree-0.1.8 docstring-parser-0.16 etils-1.9.2 googleapis-common-protos-1.63.1 immutabledict-4.2.0 importlib_resources-6.4.0 promise-2.3 protobuf-4.25.3 simple-parsing-0.1.5 tensorflow-metadata-1.15.0 tensorflow_datasets-4.9.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Gaming3\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\~upb'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary librairies\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the Mnist dataset\n",
    "mnist_dataset,minst_info = tfds.load(name='mnist',with_info=True,as_supervised='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attribute naming the dataset\n",
    "\n",
    "mnist_train,mnist_test = mnist_dataset['train'],mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 0.1 * minst_info.splits['train'].num_examples\n",
    "num_validataion_samples = tf.cast(num_validation_samples,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = minst_info.splits['train'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale function\n",
    "\n",
    "def scale(image,label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image /=255\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map the scale function \n",
    "\n",
    "scaled_train_and_validataion_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the dataset\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validataion_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validataion_samples)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validataion_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the batch size\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data= train_data.batch(BATCH_SIZE)\n",
    "validation_data=validation_data.batch(num_validataion_samples)\n",
    "test_data = mnist_test.batch(num_test_samples)\n",
    "\n",
    "#iteration\n",
    "\n",
    "validation_imputs, validataion_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaming3\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_layer_size = 50\n",
    "output_size = 10\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the optimizer and loss function\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 5s - 9ms/step - accuracy: 0.8819 - loss: 0.4100 - val_accuracy: 0.9372 - val_loss: 0.2159\n",
      "Epoch 2/5\n",
      "540/540 - 2s - 3ms/step - accuracy: 0.9491 - loss: 0.1745 - val_accuracy: 0.9520 - val_loss: 0.1613\n",
      "Epoch 3/5\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "model.fit(train_data, epochs= NUM_EPOCHS, validation_data=(validation_imputs,validataion_targets), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "test_loss,test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "print('Test loss : {0,.2f}. Test accuracy: {1:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
